Алгоритмы сортировки
Сортировка выбором (Selection Sort) — алгоритм сортировки массива путём последовательного выбора минимального элемента среди оставшихся несортированных элементов и перемещения его в начало отсортированной части массива.
Объяснение работы алгоритма:
Внешний цикл (for) Мы проходим циклом по каждому элементу массива от начала до предпоследнего включительно (i). Для каждого значения i, мы ищем наименьший элемент среди всех элементов, расположенных правее i.
Внутренний цикл (for) Во внутреннем цикле мы начинаем проверку с первого следующего элемента относительно текущего внешнего цикла (j = i+1) и идём до конца массива. Во время прохода внутреннего цикла сравниваются элементы, и запоминается позиция самого маленького из них (minIndex).
Обмен элементов После завершения внутреннего цикла, если найдена позиция другого элемента меньше текущего, выполняется обмен значений на местах позиций i и minIndex. Это перемещает минимальный элемент на позицию в отсортированную область массива.
Повторение шагов Процесс повторяется до тех пор, пока весь массив не окажется отсортированным.
Исходный массив:
64 25 12 22 11
 
Отсортированный массив:
11 12 22 25 64
Временная сложность:
Алгоритм сортировки выбором имеет временную сложность O(n²) в худшем, среднем и лучшем случаях.
 
Сортировка обменом (Bubble Sort) — это простой алгоритм сортировки, работающий путем многократного прохождения по списку и сравнения соседних элементов. Если соседние элементы расположены неправильно (не соответствуют порядку сортировки), они меняются местами. Процесс продолжается до тех пор, пока весь список не станет упорядоченным.
Объяснение работы алгоритма:
Внешний цикл (for) Проходит по массиву слева направо столько раз, сколько необходимо для полной сортировки. Каждый проход уменьшает количество потенциально неверных сравнений, так как самые большие элементы постепенно поднимаются вверх ("пузырьком").
Внутренний цикл (for) Сравнивает пары соседних элементов друг с другом и меняет их местами, если предыдущий элемент больше последующего. После завершения одного полного прохода наибольший элемент гарантированно оказывается в конце списка.
Оптимизация Используется флаг swapped, который отслеживает, происходила ли хотя бы одна перестановка на данном этапе. Если ни одной перестановки не было сделано, значит массив уже отсортирован, и дальнейшие итерации бессмысленны.
Итерация процесса Каждый новый внешний цикл сокращает диапазон проверки, поскольку самые большие элементы уже находятся на своих финальных позициях. Этот процесс повторяется до тех пор, пока массив не станет полностью отсортированным.
 
Для наглядности рассмотрим работу алгоритма на примере массива {64, 34, 25, 12, 22, 11}:
o Первый проход: {34, 25, 12, 22, 11, 64}
o Второй проход: {25, 12, 22, 11, 34, 64}
o Третий проход: {12, 22, 11, 25, 34, 64}
o Четвертый проход: {12, 11, 22, 25, 34, 64}
o Пятый проход: {11, 12, 22, 25, 34, 64}
 
Временная сложность:
Сложность пузырьковой сортировки составляет O(n²) в худшем и среднем случаях, потому что оба вложенных цикла выполняются почти целиком независимо от состояния массива. Однако в наилучшем случае (если массив уже отсортирован), производительность улучшится до O(n), благодаря оптимизации с использованием флага swapped.
 
Сортировка вставками (Insertion Sort) — это алгоритм сортировки, который последовательно строит итоговую отсортированную последовательность, помещая каждый новый элемент на свою правильную позицию среди ранее отсортированных элементов. По сути, массив делится на две части: отсортированная и неотсортированная. Алгоритм берёт очередной элемент из неотсортированной части и находит для него правильное место в отсортированной.
Объяснение работы алгоритма:
Подготовка Метод начинается с разделения массива на два сегмента: отсортированный (начиная с первого элемента) и ещё не обработанный (остальные элементы).
Выбор ключа Из неотсортированной части выбирается текущий элемент (ключ), который надо поместить в нужную позицию внутри отсортированной части.
Нахождение места Далее идёт проверка условий в обратном порядке (от конца отсортированной части к началу): если какой-то элемент больше нашего ключа, он сдвигается вправо, освобождая место.
Установка ключа Когда найдено подходящее место для ключа, он размещается там. Эти шаги повторяются до тех пор, пока вся отсортированная часть не охватит весь массив.
 
Возьмем массив {12, 11, 13, 5, 6}, пройдем пошагово:
o Начнем с первого элемента 12, считаем его отсортированным.
o Далее берем 11 и сравниваем с предыдущими элементами. Так как 11 < 12, ставим 11 перед 12. Теперь массив {11, 12, 13, 5, 6}.
o Затем обрабатываем 13, сравниваем с предыдущими элементами. Все в порядке, оставляем как есть.
o Следующим берём 5, сравниваем с предыдущими. Элементы 13, 12, 11 смещены вправо, и ставим 5 на первую позицию: {5, 11, 12, 13, 6}.
o Последним рассматриваем 6, двигаясь обратно: элемент 13 смещён, получаем {5, 6, 11, 12, 13}.
 
Временная сложность:
Худший случай: O(n²), когда массив изначально отсортирован в обратном порядке.
Лучший случай: O(n), если массив уже отсортирован заранее.
Средняя сложность: O(n²), поскольку часто приходится проверять большую часть предыдущих элементов.
 
 
 
Сортировка слиянием (Merge Sort) — это эффективный рекурсивный алгоритм сортировки, основанный на подходе "разделяй и властвуй". Он разделяет массив на две равные половины, сортирует каждую половину отдельно, а затем объединяет обе отсортированные половинки в одну общую отсортированную последовательность.
Объяснение работы алгоритма:
Разделение массива Основной принцип алгоритма состоит в том, чтобы разделить массив на две примерно равные части. Это разделение продолжается рекурсивно, пока каждая часть не сократится до единичного элемента.
Слияние отсортированных частей Каждая пара маленьких отсортированных массивов объединяется в общий отсортированный массив. Этот процесс продолжается до тех пор, пока весь исходный массив снова не соберётся вместе, но уже полностью отсортированным.
 
Пример: Рассмотрим массив {38, 27, 43, 3, 9, 82, 10}.
o Мы сначала разделяем его на две части: {38, 27, 43} и {3, 9, 82, 10}.
o Каждая из этих частей продолжает дробиться, пока не останется отдельные элементы.
o Когда всё поделено, начинается этап слияния: элементы объединяются в правильном порядке.
o Постепенно формируются небольшие отсортированные последовательности, которые сливаются в единую отсортированную структуру.
 
Временная сложность:
Лучшая, средняя и худшая случаи: O(n log n)
 
Сортировка Шелла (Shell Sort) — это улучшенная версия сортировки вставками, разработанная Дональдом Шеллом в 1959 году. Она основана на идее частичного упорядочивания элементов, используя специальные промежутки (шаги), которые уменьшаются на каждой итерации. Сначала сравниваются элементы, находящиеся далеко друг от друга, а затем промежуток уменьшается, и элементы становятся ближе, обеспечивая постепенное приближение к окончательно отсортированному состоянию.
Объяснение работы алгоритма:
Выбор начальных расстояний Алгоритм выбирает некоторое начальное расстояние (gap), которое обычно задают как половину длины массива, и затем поэтапно уменьшаем его, пока не достигнем единицы.
Частичное упорядочивание На каждом расстоянии элементы распределяются таким образом, что формируется своего рода частичный порядок. Например, на первом шаге, когда расстояние велико, удалённые элементы начинают сближаться.
Уменьшение интервала Расстояние уменьшается вдвое на каждой итерации, позволяя шаг за шагом приводить массив к полному порядку.
 
Эффективность алгоритма зависит от правильного выбора начальной величины интервала и способа уменьшения. Классический вариант (интервал Хиббарда) предполагает уменьшение вдвое на каждом шаге, но существуют и другие варианты улучшения эффективности.
 
Предположим, наш массив: {23, 12, 1, 8, 34, 56, 7}.
1. На начальном шаге интервал равен половине длины массива (72=327​=3), элементы группируются следующим образом: ({23, 1}, {12, 8}, {34, 56}, {7}).
2. Производятся частичные перестановки, и массив принимает вид: {1, 8, 12, 23, 34, 56, 7}.
3. Интервал уменьшается до 1, и на последнем шаге выполняется обычная сортировка вставками, приводя массив к виду: {1, 7, 8, 12, 23, 34, 56}.
 
Временная сложность:
 
Средняя сложность: варьируется от $\mathbf{O(n^{1.25})$ до O(n1.5)O(n1.5)
Худший случай: иногда достигает O(n2), но редко встречается на практике.
Оптимальная реализация: возможна O(n⋅logn).
 
Быстрая сортировка (Quicksort) — это высокоэффективный алгоритм сортировки, использующий стратегию "разделяй и властвуй". Его основная идея заключается в выборе опорного элемента («pivot»), разделении массива на две части относительно этого элемента и последующей рекурсивной сортировке обеих частей.
Объяснение работы алгоритма:
Выбор опорного элемента Опорный элемент (pivot) выбирается случайно или последним элементом в массиве. В нашем примере мы используем последний элемент.
Разбиение массива Затем происходит перемещение элементов так, чтобы все элементы левее опорного были меньше или равны ему, а все элементы правее — больше или равны.
Рекурсия После разбиения массив делится на две части, и рекурсивно применяется та же самая операция быстрого разбиения.
Завершение Процедура повторяется, пока не будут достигнуты минимальные подмножества (массивы длиной 1), которые автоматически являются отсортированными.
Пусть дан массив {10, 7, 8, 9, 1, 5}.
1. Выделим опорный элемент — возьмём последнее число (5).
2. Разобьем массив: числа менее 5 перейдут влево, остальные останутся справа.
3. Получим новую конфигурацию: {1, 7, 8, 9, 10, 5}.
4. Поместим опорный элемент на его правильную позицию: {1, 5, 7, 8, 9, 10}.
5. Теперь повторим операцию для левой стороны и правой стороны рекурсивно.
 
 
 
Временная сложность:
 
Средняя сложность: O(nlogn) — наиболее распространённый сценарий, достигаемый при удачном выборе опорного элемента.
Хуже всего: O(n2) — случается, если опорный элемент постоянно выбирается плохо (например, самый большой или маленький элемент).
Лучше всего: O(nlogn) — теоретически возможно, если выбор опорного элемента близок к среднему значению.
 
Пирамидальная сортировка (Heapsort) — это алгоритм сортировки, основанный на использовании структуры данных "бинарная куча" (binary heap). Куча — это полное бинарное дерево, организованное таким образом, что родительский узел всегда больше (или меньше) своих дочерних узлов. Алгоритм включает два основных этапа: формирование кучи и удаление элементов из неё в определённом порядке для построения отсортированного массива.
Объяснение работы алгоритма:
Структура программы:
1. heapSort — основная функция сортировки.
2. heapify — вспомогательная функция для построения и поддержания структуры max-кучи.
3. swap — простая процедура обмена значений двух индексов массива.
Разбор функций:
1. Метод heapSort:Этот метод реализует основную логику сортировки:
o Сначала строится полная max-куча, начиная с последней внутренней вершины (n/2 - 1) и двигаясь обратно к корню.
o Затем каждый элемент извлекается из верхушки кучи (корень) и помещается в конец массива, после чего снова производится восстановление свойств кучи.
2. Метод heapify:Эта функция поддерживает свойство max-кучи, перемещая самый большой элемент к вершине ("поднимаемся вверх"). Она получает три параметра:
o Массив arr.
o Размер кучи (size), потому что длина кучи уменьшается с каждым извлечением.
o Индекс текущего рассматриваемого узла (rootIndex).
Алгоритм действует следующим образом:
o Проверяется наличие детей слева и справа.
o Если какой-либо ребёнок больше родительского узла, он становится новым кандидатом на позицию максимального значения.
o После выбора нового кандидата, проводится обмен мест, если узел нарушен (новый кандидат отличается от родителя).
o Далее запускается рекурсия, чтобы восстановить порядок в дочерних ветвях.
3. Метод swap:Элементарный обмен значениями между двумя элементами массива.
 
Рассмотрим простой пример массива [12, 11, 13, 5, 6, 7]. Вот шаги, происходящие внутри программы:
1. Исходный массив преобразуется в max-кучу: [13, 11, 12, 5, 6, 7]
2. Корень (13) меняется с последним элементом (7), новый массив: [7, 11, 12, 5, 6, 13], затем выполняется ещё одна операция восстановления кучи над первым элементом.
3. Процесс повторяется для остальных элементов, пока массив не станет упорядоченным: [5, 6, 7, 11, 12, 13].
 
Временная сложность:
o Для формирования начальной max-кучи: O(N), поскольку каждая вершина обрабатывается максимум за logN операций.
o Для извлечения всех элементов и их помещения в правильную позицию: O(NlogN).
Таким образом, общая временная сложность алгоритма пирамидальной сортировки составляет: O(NlogN)
 
Последовательный поиск (также известный как линейный поиск) — это простейший алгоритм поиска заданного элемента в списке путём последовательного просмотра всех элементов списка от начала до конца. Поиск останавливается либо тогда, когда найден искомый элемент, либо пройден весь список без нахождения такого элемента.
Объяснение работы алгоритма:
Метод linearSearch
o public static int linearSearch(int[] array, int target):
o Объявляется публичный статический метод linearSearch, принимающий два аргумента: массив целых чисел array и целевой элемент target, который мы ищем.
o Внутри цикла for проходит проверка каждого элемента массива:
o if (array[i] == target):
o Здесь сравниваются текущий элемент массива с целевым числом.
o Если совпадение найдено, возвращается индекс элемента (i).
o После завершения проверки всего массива:
o Если элемент не найден, возвращается значение -1, означающее отсутствие искомого числа в массиве.
Метод main
Этот метод служит демонстрационным примером использования метода linearSearch:
o Создается тестовый массив data и переменная key, представляющая число, которое мы хотим найти.
o Вызываем метод linearSearch, передавая созданный массив и ключ.
o Результат выводится на экран, показывая успешность поиска.
 
Алгоритм последовательно перебирает каждый элемент массива, проверяя, совпадает ли он с искомым значением. Рассмотрим пошагово работу на примере:
Пример: Пусть дан массив {3, 8, 1, 10, 5}, и нам нужно найти элемент 10.
1. Начинаем проверку с первого элемента:
o Первый элемент — 3, он не равен 10, продолжаем дальше.
2. Второй элемент — 8, тоже не подходит.
3. Третий элемент — 1, пропускаем.
4. Четвёртый элемент — 10, совпал!
5. Так как найдена нужная цифра, возвращаем её индекс (3).
 
Временная сложность:
Лучшая ситуация: O(1) — когда первый же элемент оказывается искомым.
Средняя ситуация: O(N2)— примерно половина массива должна быть проверена.
Худшая ситуация: O(N)— когда элемент находится в конце массива или вовсе отсутствует.
 
Бинарный поиск — это эффективный алгоритм поиска элемента в отсортированном массиве или списке. Его суть заключается в следующем:
o Каждый шаг уменьшает область поиска вдвое, сокращая количество возможных кандидатов на присутствие искомого элемента.
o Происходит это путём сравнения среднего элемента области поиска с искомым значением и дальнейшего сужения диапазона в зависимости от результата сравнения.
Объяснение работы алгоритма:
Класс BinarySearch
1. Основной метод binarySearch:
o Метод принимает два аргумента: отсортированный массив array и искомое значение target.
2. Инициализация границ поиска:
o Переменные low и high хранят границы области поиска. Изначально это соответственно первая и последняя позиция массива.
3. Цикл поиска:
o Цикл продолжается, пока нижняя граница не превысит верхнюю.
o На каждом шаге вычисляется середина области поиска.
o Среднее значение сравнивается с целью:
o Если оно равно цели, сразу возвращаем индекс.
o Если среднее значение меньше цели, значит, цель расположена правее, и мы обновляем нижнюю границу.
o Если среднее значение больше цели, цель находится левее, и верхняя граница сдвигается.
4. Возвращение результата:
o Если цикл завершился без успешного обнаружения, возвращаем -1, обозначая неудачу поиска.
Демонстрационный метод main
Здесь создаётся небольшой отсортированный массив и демонстрируется работа метода бинарного поиска. Например, ищем число 7 в массиве {1, 3, 5, 7, 9, 11}:
o На первом шаге средняя точка равна 5, она меньше цели (7), следовательно, следующая итерация начинается с верхней половины массива.
o Следующая средняя точка — это 7, она совпадает с искомым значением, и поиск успешно завершён.
 
Пусть дано отсортированное множество чисел: [1, 3, 5, 7, 9, 11], и надо найти число 7.
Шаг 1: Средняя точка — это элемент 5, который меньше 7, следовательно, следующий диапазон — [7, 9, 11].
Шаг 2: Новая средняя точка — это сам элемент 7, и он соответствует нашему запросу.
 
Временная сложность:
Лучший случай: O(1) — если искомый элемент оказался ровно посередине массива.
Средний и худший случаи: O(logN) — каждое сравнение разделяет массив пополам, и за счёт деления пополам достигается быстрая константная скорость роста.
 
Интерполирующий поиск — это улучшенный вариант бинарного поиска, предназначенный для быстрого поиска элементов в больших отсортированных наборах данных с равномерным распределением значений. Вместо простого разделения массива пополам, этот алгоритм пытается предсказать положение искомого элемента на основе разницы между минимальным и максимальным значениями массива и самим искомым значением.
Объяснение работы алгоритма:
Класс InterpolationSearch
1. Основной метод interpolationSearch:
o Принимает два аргумента: отсортированный массив array и искомое значение target.
2. Инициализация границ поиска:
o Переменные low и high задают начальные границы области поиска.
3. Формула расчёта средней точки:
o Ключевая особенность интерполирующего поиска — расчёт приближённого положения искомого элемента на основе распределения данных:pos = low + (((double)(high - low) / (array[high] - array[low])) * (target - array[low]))Это уравнение даёт оценку ожидаемой позиции целевого элемента исходя из расстояния между нижней границей и искомым значением относительно общего диапазона массива.
4. Проверка условий поиска:
o Пока нижняя граница меньше или равна верхней, и цель лежит в диапазоне между ними, цикл продолжает свою работу.
5. Обработка результатов сравнения:
o Если целевой элемент точно обнаружен, немедленно возвращаем его индекс.
o Если цель оказалась левее предположенной позиции, переустанавливаем нижнюю границу.
o Если цель правее, сдвигаем верхнюю границу.
6. Результат поиска:
o Если цикл завершил своё выполнение, и ничего не было найдено, возвращаем -1.
Метод main
Здесь демонстрируется использование метода на практике. Мы передаём отсортированный массив и ожидаем увидеть, как быстро наш алгоритм находит нужное значение.
Например, пусть наш массив выглядит так: [10, 15, 20, 25, 30, 35, 40, 45, 50], и мы ищем число 35.
1. Начнём с первой итерации:
o Расчёт позиции показывает, что наше предположение близко к середине.
o Сравниваем элемент в предполагаемой позиции с нашим целевым значением.
o Поскольку это точное попадание, алгоритм возвращает соответствующий индекс.
 
Временная сложность:
Лучший случай: O(1) — если искомый элемент находится прямо там, куда указал алгоритм.
Средний случай: O(log(logN)) — благодаря точной оценке следующей позиции и быстрым переходам, временная сложность лучше стандартной бинарной логарифмической.
Худший случай: O(N) — если распределение данных неравномерное или разбросанное, поведение деградирует до поведения стандартного последовательного поиска.
 
Фибоначчи-поиск — это усовершенствованный алгоритм поиска, использующий последовательность чисел Фибоначчи для эффективного поиска элементов в отсортированном массиве. Основное отличие от классического бинарного поиска состоит в том, что деление массива на две части осуществляется на основании последовательности Фибоначчи, что позволяет уменьшить размер исследуемой области быстрее.
Объяснение работы алгоритма:
Класс FibonacciSearch
1. Метод fibonacciSearch:
o Получает два аргумента: отсортированный массив array и искомое значение x.
2. Вычисление нужного числа Фибоначчи:
o Использует внутренний метод findMinFibonacciNumberGreaterOrEqualTo, чтобы найти первое число Фибоначчи, большее или равное размеру массива.
3. Определение начальной позиции поиска:
o Устанавливаем начальное смещение offset = -1, используем первые два числа Фибоначчи (f1=0, f2=1), а третье (nextF=m) используется для дальнейших расчетов.
4. Процесс поиска:
o Продолжаем процесс, пока величина следующего числа Фибоначчи (nextF) больше единицы.
o Рассчитываем промежуточную позицию на основе последнего числа Фибоначчи и смещенного индекса.
o Определяем дальнейшие действия в зависимости от результата сравнения:
o Если текущий элемент меньше искомого, движемся вправо.
o Если текущий элемент больше искомого, движемся влево.
o Если элемент совпадает, возвращаем его индекс.
5. Завершение поиска:
o Если последний этап обработки оставшихся элементов не нашел совпадения, возвращаем -1, сигнализируя об отсутствии элемента.
Внутренний метод findMinFibonacciNumberGreaterOrEqualTo
Эта функция генерирует числа Фибоначчи, пока не найдет такое, которое превышает длину массива, обеспечивая основу для оптимального деления массива на меньшие части.
Тестовая функция main
Демонстрирует работу алгоритма на конкретном примере. Массив [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100] передается вместе с искомым элементом 85. Результатом будет сообщение о том, что элемент найден на определенном индексе.
Допустим, имеем массив [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100], и нам нужно найти элемент 85.
1. Первое подходящее число Фибоначчи для размера массива (11 элементов): 13.
2. Первая попытка поиска:
o Смещаемся на позицию, соответствующую первому числу Фибоначчи: (13 - 8)/13*11 ≈ 3.
o Проверяем элемент на позиции 3 (40), это меньше нашего искомого элемента, двигаемся вправо.
3. Вторая попытка:
o Новое смещение и проверка: ((13 - 5)/13)*11 ≈ 6.
o Теперь проверяем элемент на позиции 6 (80), это меньше нашей цели, двигаемся далее.
4. Третья попытка:
o Попадание в элемент на позиции 8 (85), возвратим индекс.
 
Временная сложность:
Лучший случай: O(1)— если искомый элемент попадает именно туда, куда мы попали с первого раза.
Средний и худший случаи: O(logϕ​(N)), где ϕ=(корень5+1)/2(золотое сечение).